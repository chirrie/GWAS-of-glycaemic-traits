{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc569ef-248d-443a-9b93-2f8174c1570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Explorative-FG.R\n",
    " ##a script to generate  descriptive statistics of the data\n",
    "\n",
    "### Count total samples\n",
    "setwd(\"/Users/vivienchebii/Documents/awi-new/FG_final-Nov/\")\n",
    "FG<-read.csv (\"/Users/vivienchebii/Documents/awi-new/FG_final-Nov/FG_phenotype-12.csv\")\n",
    "total_samples <- nrow(FG)  \n",
    "View(total_samples)\n",
    "### Summary/descriptive statistics for bmi_c_qc \n",
    "summary(FG$bmi_c_qc, na.rm=TRUE)\n",
    "sd(FG$bmi_c_qc, na.rm =TRUE)\n",
    "range(FG$bmi_c_qc, na.rm = TRUE)\n",
    "mean(FG$bmi_c_qc, na.rm = TRUE)\n",
    "median(FG$bmi_c_qc)\n",
    "quantile(FG$bmi_c_qc,probs=0.5)\n",
    "####Summary for age\n",
    "summary(FG$age)\n",
    "range(FG$age)\n",
    "mean(FG$age)\n",
    "median(FG$age)\n",
    "sd(FG$age, na.rm =TRUE)\n",
    "quantile(FG$ageprobs=0.5)\n",
    "\n",
    "#### Summary of FG concerntrations\n",
    "summary(FG$glucose_qc, na.rm=TRUE)\n",
    "sd(FG$glucose_qc,na.rm=TRUE)\n",
    "range(FG$glucose_qc, na.rm=TRUE)\n",
    "mean(FG$glucose_qc,na.rm=TRUE)\n",
    "median(FG$glucose_qc, na.rm=TRUE)\n",
    "\n",
    "### Count the total number of females and males and convert  to percentbmi_c_qc\n",
    "table(FG$sex)\n",
    "(percent_gender <- table(FG$sex)/total_samples * 100)\n",
    "### Create a bar plot for males and females to get an idea of the distribution\n",
    "(percent_gender <- table(FG$sex)/total_samples * 100)\n",
    "table(percent_gender)\n",
    "barplot(percent_gender,ylim=c(0,100), ylab=\"Percentage of individuals\",xlab=\"Sex(0=F,1=M)\", main=\"Barplot of gender \")\n",
    "###Plots for BMI classiFGcations\n",
    "percent_bmi_cat <- table(FG$bmi_cat_c_qc)/total_samples * 100\n",
    "table (percent_bmi_cat)\n",
    "barplot(percent_bmi_cat,ylim=c(0,100), ylab=\"Percentage of individuals\",xlab=\"BMI_c(0=under,1=normal, 2=over, 3=obese)\", main=\"Barplot of BMI Catagory\")\n",
    "\n",
    "####Diabetic status \n",
    "percent_diabetics <- table(FG$diabetes_status_c_qc)/total_samples * 100\n",
    "table(percent_diabetics)\n",
    "barplot(percent_diabetics,ylim=c(0,100), ylab=\"Percentage of individuals\",xlab=\"Diabetics_status(0=Non diabetics,1=Diabetics)\", main=\"Barplot of Diabetic Status (FG trait)\")\n",
    "\n",
    "### Calcualter skeweness of contionus data \n",
    "install.packages(\"moments\")\n",
    "install.packages(\"ggpubr\")\n",
    "library(moments)\n",
    "library(ggpubr)\n",
    "skewness(FG$glucose_qc, na.rm = TRUE)\n",
    "###Logtransform and inverse transformation and  Density plots for continous variables\n",
    "##Age \n",
    "install.packages(\"rcompanion\")  ###for inverse normalization\n",
    "install.packages(\"GDAdata\")\n",
    "library(rcompanion)\n",
    "par(mfrow=c(1,2))\n",
    "\n",
    "logtransform<-log10(FG$glucose_qc)\n",
    "inverse_trans<-blom(FG$glucose_qc, method=\"blom\", alpha=3/8, complete=TRUE)\n",
    "par(mfrow=c(1,3))\n",
    "plot(density(FG$glucose_qc, na.rm=TRUE, bw = 1), col = \"black\", main = \"untransformed FG\", ylim = c(0,0.4), xlab=\"FG(uIU/ml\")\n",
    "plot(density(logransform, na.rm=TRUE, bw = 1), col = \"black\", main = \"log_transformed FG\", ylim = c(0,0.4), xlab=\"FG\")\n",
    "plot(density(inverse_trans, na.rm=TRUE, bw = 1), col = \"black\", main = \"inverse_normaltransformed FG\", ylim = c(0,0.4), xlab=\"FG\")\n",
    "hist(FG$glucose_qc,col= 'grey', main = 'Distribution of FG',xlab = 'FG (mmol/l)', ylab='No of individuals', breaks= c(30))\n",
    "hist(logtransform,col= 'grey', main = 'logtranformed-FG',xlab = 'FG (mmol/l)', ylab='No of individuals', breaks= c(30))\n",
    "hist(inverse_trans,col= 'grey', main = 'inversetransformed-FG',xlab = 'FG (mmol/l)', ylab='No of individuals', breaks= c(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda42e2-48a8-4763-9cf1-d7903ab693dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "2. 1000g-pop-specific-plink.sh\n",
    "\n",
    "Description: Plink command to extract the genotype data from various sub populations in the 1000 genomes database\n",
    "Inputs: 1000 genome plink files and data for each sub populations\n",
    "Outputs: Plink files\n",
    "Usage:\n",
    "#!/bin/env bash\n",
    "#SBATCH -p batch\n",
    "##SBATCH -w n27\n",
    "#SBATCH -J plink\n",
    "#SBATCH -c 10 ##number of cores\n",
    "#SBATCH --mem=10G\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "\n",
    "module load plink\n",
    "\n",
    "plink --threads 16 --bfile updated_1000 --keep Eas.samples.txt --make-bed --out EAS\n",
    "\n",
    "plink --threads 16 --bfile updated_1000 --keep african-id.txt --make-bed --out African-b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3a6d8-cd55-431d-bbda-466de759fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. gwas-boltlmm-bmiadj.sbatch\n",
    " Linear mixed model script for running GWAS analysis for combined dataset, implimented in BOLTLMM program takes >5000 samples hence used for combined set gwas analysis\n",
    "  #!/bin/env bash\n",
    "#SBATCH -p batch\n",
    "##SBATCH -w n27\n",
    "#SBATCH -J bolt-HOMA-r\n",
    "#SBATCH -c 8 ##number of cores\n",
    "#SBATCH --mem=30000\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "\n",
    "module load bioinf\n",
    "module load python/3.9\n",
    "module load bolt\n",
    "\n",
    "bolt --bfile=~/all_imputed_map_qc --phenoFile=HOMA-IR.txt --phenoCol=log10_HOMA-IR --covarFile=HOMA-IR.txt --covarCol=sex --qCovarCol=PC{1:8} --qCovarCol=age --qCovarCol=bmi_c_qc --lmm --lmmForceNonInf --LDscoresFile=~/LDSCORE.1000G_AFR.tab.gz --numThreads=16 --maxModelSnps=1014126 --modelSnps=~/RsModelImput/rs_All_model_100_20_0.6 --geneticMapFile=~/genetic_map_hg19_withX.txt.gz --statsFile=HOMA-ir-undjustbmi.tab --impute2FileList=~/file_impute2 --impute2FidIidFile=~/score_imputed_data/FidIidFile.impute2 --statsFileImpute2Snps=HOMA-IR-unadjustbmi.stat\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df348fe9-bb5f-461d-b35d-af44897d06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Regenie.sbatch\n",
    " Linear mixed model script using REGENIE which works well for small sample sizes. This was used for regionwise gwas\n",
    " !/bin/env bash\n",
    "##SBATCH -w n06\n",
    "#SBATCH -J fe-raw\n",
    "#SBATCH -c 8 ##number of cores\n",
    "#SBATCH --mem=30000\n",
    "##SBATCH --error slurm-A%.out\n",
    "\n",
    "module load regenie/3.4.1\n",
    "### do this :conda activate regenie_env\n",
    "\n",
    "regenie --threads 8 --step 1 --force-step1 --bed /~/regen/regen-ldpruned --phenoFile FG-south.txt --phenoCol glucose_qc --covarFile FG-south.txt --covarCol age --covarCol Age2 --covarCol PC{1:6} --strict --bsize 1000 --qt --lowmem --write-samples --out FG-south-raw-step1\n",
    "\n",
    "\n",
    "\n",
    "regenie --threads 8 --step 2 --bed ~/imputed_data_plink/all_imputed_map_qc --phenoFile FG-south.txt --phenoCol glucose_qc --covarFile FG-south.txt --covarCol age --covarCol Age2 --covarCol PC{1:6} --strict --bsize 200 --qt --lowmem --pred FG-south-raw-step1_pred.list --out FG-south-bmiunadj\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa006843-27e3-48b4-8819-0fda3d7b2bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. popcorn.sh\n",
    "  A script for running cross ancestry genetic correlation using POPCORN tool. AWI-GEN and public available GWAS data were used\n",
    " #!/bin/env bash\n",
    "#SBATCH -p batch\n",
    "##SBATCH -w n27\n",
    "#SBATCH -J Popcorn-cor\n",
    "#SBATCH -c 8 ##number of cores\n",
    "#SBATCH --mem=30000\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "module load python/2.7.10 \n",
    "#####Script for running crosss-ancestry genetic correlation\n",
    "\n",
    "popcorn compute --maf 0.01 --bfile1 ~/imputed_data_plink/all_imputed_map_qc --bfile2 European-b --gen_effect  AWI_EUR-b.cscore\n",
    "\n",
    "\n",
    "\n",
    "popcorn fit --use_mle --cfile AWI_EUR-b.cscore --gen_effect --sfile1 FG-awi-gen.txt --sfile2 magic-eur.txt AWI-FG-EUR_nomun-correlation.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927af8f-cafb-44bd-ac4a-839101aa5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. gwas_data_cleanup.sh\n",
    "A script for cleaning gwas results before running genetic correlation using POPCORN\n",
    "#README\n",
    "\n",
    "\n",
    "#Format gwas files magic data\n",
    "#Below scripet replaces he headers with popcorn specific format\n",
    "\n",
    "sed '1s/.*/SNP\\tchr\\tpos\\tA2\\tA1\\tAF\\tbeta\\tSE\\tP\\tN/' MAGIC100i0G_FG_AA.tsv>output_file.txt\n",
    "\n",
    "### omit p value column\n",
    "\n",
    "awk '{for(i=1;i<=NF;i++) if(i!=9) printf \"%s%s\", $i, (i==NF ? \"\\n\" : OFS)}' OFS=\"\\t\" output_file.txt> magic-eur.txt\n",
    "\n",
    "\n",
    "#### remove SNPs with missing data and structrural variants\n",
    "\n",
    "grep -v \"NA\" magic-eur.txt >m.txt\n",
    "\n",
    "mv m.txt magic-eur.txt \n",
    "awk 'NR==1 || ($4 ~ /^[ACGT]$/ && $5 ~ /^[ACGT]$/)' magic-eur.txt >magic-eur-clean.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e29c577-4ee8-4b6b-805b-a9f44c9fd2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. updated-rsids-1000genomes.sh\n",
    " A script for updating rsids in 1000 genomes as a preparation step for running genetic correlation using POPCORN\n",
    " #!/bin/env bash\n",
    "#SBATCH -p batch\n",
    "#SBATCH -w n02\n",
    "#SBATCH -J plink\n",
    "#SBATCH -c 10 ##number of cores\n",
    "#SBATCH --mem=10G\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "\n",
    "module load plink  \n",
    "\n",
    "#script to update rsids in 1g plink files\n",
    "\n",
    "awk 'FNR==NR {a[$1\":\"$2]=$3; next} {if($1\":\"$4 in a) print $2, a[$1\":\"$4]}' reference.txt 1000g-b.bim > mapping.txt\n",
    "\n",
    "plink --bfile kg --update-name mapping.txt 2 1 --make-bed --out updated_1g\n",
    "##### remove duplicates SNPS\n",
    "plink --bfile updated_1g --extract snps_to_keep.txt --make-bed --out updated_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48354f-ef9c-4063-82c4-a16447b0fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Manhattan-qq.r\n",
    "A script to generate Manhattan and qq plots of the gwas results\n",
    "\n",
    "png(\"FI—maleINT-manp.png\", width=2000,height=800,res=150)\n",
    " par(mar = c(5.1, 4.1, 1.1, 2.1))\n",
    "par(las=1)\n",
    "xlas=2\n",
    "manhattan(FG, chr=\"CHR\", bp=\"BP\", snp=\"SNP\", p=\"P_BOLT_LMM\", logp = TRUE, main = \"Manhattan Plot\", ylim = c(0, 8),cex = 0.6, cex.axis = 0.9,xlab = \"Chromosome\",col = c(\"steelblue4\", \"orange3\"), suggestiveline = 1e-6, genomewideline = 5e-08) \n",
    "dev.off()\n",
    "\n",
    " png(\"FI-male-INT-qq.png\", width=1000,height=500,res=150)\n",
    " par(mar = c(5.1, 4.1, 1.1, 2.1))\n",
    "xlas=2\n",
    "   qq(10^-male$LOG10P, main = \"Q-Q plot of GWAS p-values\")\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf9e8e-a99b-4317-a363-ec4e0d87571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. merge-images.R\n",
    " ### Script for merging manhattan and locuszoom plots\n",
    "# Load the magick package\n",
    "library(magick)\n",
    "\n",
    "# Read the two images\n",
    "image1 <- image_read(\"/Users/vivienchebii/Documents/new-plots/Manhatan-FG24.png\")  # Replace with your file path\n",
    "image2 <- image_read(\"/Users/vivienchebii/Documents/new-plots/FG-locuszoom.png\")  # Replace with your file path\n",
    "\n",
    "# Get dimensions of the images\n",
    "dim1 <- image_info(image1)\n",
    "dim2 <- image_info(image2)\n",
    "\n",
    "# Check the heights of both images\n",
    "height1 <- dim1$height\n",
    "height2 <- dim2$height\n",
    "\n",
    "# Resize the larger image to match the height of the smaller one\n",
    "if (height1 > height2) {\n",
    "  image1 <- image_resize(image1, paste0(dim2$width, \"x\", height2, \"!\"))  # Resize image1 to match height2\n",
    "} else if (height2 > height1) {\n",
    "  image2 <- image_resize(image2, paste0(dim1$width, \"x\", height1, \"!\"))  # Resize image2 to match height1\n",
    "}\n",
    "\n",
    "# Combine the images vertically\n",
    "combined_image <- image_append(c(image1, image2), stack = TRUE)\n",
    "\n",
    "# Display the combined image\n",
    "print(combined_image)\n",
    "\n",
    "# Save the combined image (optional)\n",
    "image_write(combined_image, path = \"combined_image.jpg\", format = \"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd86c8f-7a5a-460b-90a3-ad9907b9dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Finemapping-windowbased.sh\n",
    "\n",
    "\n",
    "#SBATCH -w n02\n",
    "#SBATCH -J finemap2\n",
    "#SBATCH -c 12 ##number of cores\n",
    "#SBATCH --mem=30000\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "\n",
    "module load bioinf\n",
    "module load python/3.9\n",
    "module load java/18\n",
    "rm -rf ~/.nextflow/assets/h3abionet/\n",
    "#rm ~/.singularity/*.img\n",
    "nextflow pull h3abionet/h3agwas\n",
    "\n",
    "nextflow run  h3abionet/h3agwas/finemapping/finemap_region.nf --begin_seq 31700274 --end_seq 32161594 --chro 18 --head_pval P_BOLT_LMM --head_bp BP --head_chr CHR --head_rs SNP --head_beta BETA --head_se SE --head_A1 ALLELE1 --head_A2 ALLELE0 --input_dir \"~/shared/imputed_data_plink/\" --input_pat all_imputed_map_qc --file_gwas \"~/FG_raw/boltlmm/all_imputed_map_qc\n",
    "-glucose_qc.imp.stat\" --list_phenogc \"Fasting glucose\" --output_dir \"~/FG_raw/finemap24\" --output finemapping_FG24 -profile slurmSingularity -r dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f783285-19d7-4812-8a36-5c8fcf75c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Finemapping.sbatch :Fine mapping based on rsids\n",
    "\n",
    "#!/bin/env bash\n",
    "#SBATCH -p batch\n",
    "#SBATCH -w n02\n",
    "#SBATCH -J finemap2\n",
    "#SBATCH -c 12 ##number of cores\n",
    "#SBATCH --mem=30000\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "\n",
    "module load bioinf\n",
    "module load python/3.9\n",
    "module load java/18\n",
    "\n",
    "nextflow pull h3abionet/h3agwas\n",
    "\n",
    "nextflow run  h3abionet/h3agwas/finemapping/main.nf --head_pval P_BOLT_LMM --head_bp BP --head_chr CHR --head_rs SNP --head_beta BETA --head_se SE --head_A1 ALLELE1 --head_A2 ALLELE0 --input_dir \"~/imputed_data_plink/\" --input_pat all_imputed_map_qc --file_gwas \"~/FG.stat\" --list_phenogc \"Fasting blood glucose\" --output_dir \"~/Awi-gen/FG_raw/finemap24\" --output finemapping_FG24 -profile slurmSingularity -r dev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c496b0-f05b-44ca-ac16-6a07d40585c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "12: cojo.sbatch: script for conditional analysis to identify secondary signals\n",
    "#SBATCH -p batch\n",
    "#SBATCH -w n02\n",
    "#SBATCH -J cojo\n",
    "#SBATCH -c 8 ##number of cores\n",
    "#SBATCH --mem=30000\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "\n",
    "module load bioinf\n",
    "module load python/3.9\n",
    "\n",
    "nextflow pull h3abionet/h3agwas\n",
    "## update the pipeline\n",
    "nextflow run h3abionet/h3agwas/finemapping/cojo-assoc.nf --head_pval P_BOLT_LMM --head_bp BP --head_chr CHR --head_rs SNP --head_beta BETA --head_se SE --head_A1 ALLELE1 --head_A2 ALLELE0 --input_dir \"/dataE/AWIGenGWAS/shared/imputed_data_plink/\" --input_pat all_imputed_map_qc --output_dir cojo --data FG_phenotype.txt --pheno glucose_log --file_gwas \"/home/chebii/Awi-gen/FG-assoc/all_imputed_map_qc-glucose_log.imp.stat\" -profile slurmSingularity -r dev --cojo_top_snps_chro 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4c594-6300-42aa-8a26-6cfcd9e8d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "13: 1000g-pop-specific-plink.sh- script for extraction genome data from sub-populations in 1000 human genomes using plink\n",
    "\n",
    "#!/bin/env bash\n",
    "#SBATCH -p batch\n",
    "##SBATCH -w n27\n",
    "#SBATCH -J plink\n",
    "#SBATCH -c 10 ##number of cores\n",
    "#SBATCH --mem=10G\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "\n",
    "module load plink\n",
    "\n",
    "\n",
    "plink --threads 16 --bfile updated_1000 --keep Eas.samples.txt --make-bed --out EAS\n",
    "\n",
    "plink --threads 16 --bfile updated_1000 --keep african-id.txt --make-bed --out African-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0351662c-ac46-4095-b9ee-bf7ec95ce5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "14:gcta.sbatch -script to estimate snp heritability and correlation of the quantitative traits \n",
    "\n",
    "#!/bin/env bash\n",
    "#SBATCH -p batch\n",
    "##SBATCH -w n02\n",
    "#SBATCH -J gcta\n",
    "#SBATCH -c 8 ##number of cores\n",
    "#SBATCH --mem=30000\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "\n",
    "\n",
    "./gcta-1.94.1 --bfile ~/imputed_data_plink/all_imputed_map_qc --make-grm --out FI_test --thread-num 10\n",
    "\n",
    "\n",
    "./gcta-1.94.1 --reml --grm FI_test --pheno FI.phen --qcovar 8pcs.txt --out FI_he --thread-num 10\n",
    "\n",
    "./gcta64 --grm mydata_allSNPs --pheno mydata.phen --reml-bivar 1 2 for geneti corraltion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c152c69-b30b-4fb1-b9a3-35e81d3d5ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "15:swap-alleles.sh- A script to flip alleles in the data to match the reference genome\n",
    "\n",
    "awk 'NR==FNR { \n",
    "    # Store reference alleles in an array\n",
    "    ref[$1] = $2; \n",
    "    alt[$1] = $3; \n",
    "    next; \n",
    "} \n",
    "{\n",
    "    # Check if SNP exists in reference\n",
    "    if ($1 in ref) { \n",
    "        # Compare REF and ALT in GWAS with REF and ALT in reference\n",
    "        if ($2 != ref[$1] || $3 != alt[$1]) {\n",
    "            # Swap alleles and negate BETA if they do not match\n",
    "            print $1, alt[$1], ref[$1], -$4;\n",
    "        } else {\n",
    "            # If they match, print as it is\n",
    "            print $0;\n",
    "        }\n",
    "    } else {\n",
    "        # Print line if SNP is not found in reference\n",
    "        print $0;\n",
    "    }\n",
    "}' 1000-rsi.vcf FG.stat > swapped_gwas_data.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c5edd0-1c3f-4303-aedf-daedc885f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "16. gwas_data_formating-for-popcorn.sh- bash script to format and clean gwas summary stat file for use by POPCORN program\n",
    "\n",
    "\n",
    "#README\n",
    "\n",
    "\n",
    "#Format gwas files magic data\n",
    "#Below scripet replaces he headers with popcorn specific format\n",
    "\n",
    "sed '1s/.*/SNP\\tchr\\tpos\\tA2\\tA1\\tAF\\tbeta\\tSE\\tP\\tN/' MAGIC100i0G_FG_AA.tsv>output_file.txt\n",
    "\n",
    "### omit p value column\n",
    "\n",
    "awk '{for(i=1;i<=NF;i++) if(i!=9) printf \"%s%s\", $i, (i==NF ? \"\\n\" : OFS)}' OFS=\"\\t\" output_file.txt> magic-eur.txt\n",
    "\n",
    "\n",
    "#### remove SNPs with missing data and structrural variants\n",
    "\n",
    "grep -v \"NA\" magic-eur.txt >m.txt\n",
    "\n",
    "mv m.txt magic-eur.txt \n",
    "awk 'NR==1 || ($4 ~ /^[ACGT]$/ && $5 ~ /^[ACGT]$/)' magic-eur.txt >magic-eur-clean.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d6a47-5bee-4ab5-839d-cd092903606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "17. 1000-genomes-rsid-update.sh- A script to update 1000 genomes rsid\n",
    "\n",
    "#!/bin/env bash\n",
    "#SBATCH -p batch\n",
    "#SBATCH -w n02\n",
    "#SBATCH -J plink\n",
    "#SBATCH -c 10 ##number of cores\n",
    "#SBATCH --mem=10G\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "\n",
    "module load plink\n",
    "\n",
    "#script to update rsids in 1g plink files\n",
    "\n",
    "#awk 'FNR==NR {a[$1\":\"$2]=$3; next} {if($1\":\"$4 in a) print $2, a[$1\":\"$4]}' reference.txt 1000g-b.bim > mapping.txt\n",
    "\n",
    "#plink --bfile kg --update-name mapping.txt 2 1 --make-bed --out updated_1g\n",
    "##### remove duplicates SNPS\n",
    "plink --bfile updated_1g --extract snps_to_keep.txt --make-bed --out updated_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7945e55-5dda-4f67-8a94-da4716e6e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "18:site-pcs.sbatch\n",
    "\n",
    "#### A script to perform  pca, in this case regionwise pcs\n",
    "\n",
    "#!/bin/env bash\n",
    "#SBATCH -p batch\n",
    "#SBATCH -J flashpca\n",
    "#SBATCH -c 16 ##number of cores\n",
    "#SBATCH --mem=16000\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "\n",
    "\n",
    "./flashpca_x86-64 --bfile nai-clean-ldpruned --numthreads 16 -d 10 --outpc ~/nai2-flash.pc --outval ~/sitewise/nai2-flash-val \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185333f-f5e7-44e0-8441-227d176325e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "19: qc2.sbatch-Help scripts used to recheck data QC\n",
    "#!/bin/env bash\n",
    "#SBATCH -p batch\n",
    "#SBATCH -w n27\n",
    "#SBATCH -J qc\n",
    "#SBATCH -c 4 ##number of cores\n",
    "#SBATCH --mem=16000\n",
    "##SBATCH --error slurm-A%.out\n",
    "##SBATCH --array=1-8\n",
    "\n",
    "##/opt/exp_soft/bioinf/bin\n",
    "module load plink\n",
    "\n",
    "##Filter samples and variants with high missing entry frequencies\n",
    "###--bfile species the plink files\n",
    "##“–geno 0.1” tells PLINK to throw out every variant where more than 10% of the genotype calls are “NA”s.\n",
    "##“–mind 0.1” tells PLINK to throw out every sample where more than 10% of the genotype calls are “NA”s.\n",
    "##--make-bed generates a new PLINK 1 fileset, with the high-missingness samples and variants removed.\n",
    "\n",
    "\n",
    "plink --threads 4 --memory 16000  --bfile ./dataE/AWIGen/.. --geno 0.1 --mind 0.1 --make-bed --out missingness_filtered_data\n",
    "\n",
    "\n",
    "\n",
    "####Remove close relatives from the data using --king-cutoff parameter\n",
    "##KING kinship coefficients are scaled such that duplicate samples have kinship 0.5, not 1. \n",
    "##First-degree relations (parent-child, full siblings) correspond to ~0.25, second-degree relations correspond to ~0.125, etc. \n",
    "#It is conventional to use a cutoff of ~0.354 (the geometric mean of 0.5 and 0.25) to screen for monozygotic twins and duplicate samples, ~0.177 to add first-degree relations\n",
    "\n",
    "/opt/exp_soft/bioinf/bin/plink2 --threads 4 --memory 16000 --bfile missingness_filtered_data --king-cutoff 0.177 --make-bed --out relpruned_data\n",
    "\n",
    "\n",
    "###MAF reporting and filtering using -freq and -maf\n",
    "\n",
    "plink --threads 4 --memory 16000 --bfile missingness_filtered_data --freq --out allele_freqs\n",
    "\n",
    "plink --threads 4 --memory 16000 --bfile missingness_filtered_data  --maf 0.05 --make-bed --out maf_filtered_data\n",
    "\n",
    "#### check Hardy–Weinberg Equilibrium\n",
    "\n",
    "plink --threads 4 --memory 16000 --bfile maf_filtered_data --hardy --out hwe_values\n",
    "\n",
    "/opt/exp_soft/bioinf/bin/plink2 --threads 4 --memory 16000 --bfile maf_filtered_data --hwe 0.000001 --make-bed --out hwe_filtered_data \n",
    "\n",
    "\n",
    "\n",
    "##LD pruning. High LD regions are removed using --indep-pairwise\n",
    "##removes SNPs so that no pair within 200 kilobases have squared-allele-count-correlation (r2) greater than 0.5, and saves the IDs of the remaining SNPs to ldpruned_snplist.prune.in. \n",
    "/opt/exp_soft/bioinf/bin/plink2 --threads 4 --memory 16000 --bfile hwe_filtered_data --indep-pairwise 200kb 1 0.5 --out ldpruned_snplist\n",
    "plink --threads 4 --memory 16000 --bfile hwe_filtered_data --extract ldpruned_snplist.prune.in --make-bed --out ldpruned_data\n",
    "\n",
    "#### Check for cryptic relatenss using --genome to get pi-hat values (ibd)\n",
    "\n",
    "plink --threads 4 --memory 16000 --bfile ldpruned_data --genome --out duplicates\n",
    "###3 Extract hits with pi-hat >0.1875 and save in a file say  IBS_exlcuded.txt and run below plink command to get clean one\n",
    "\n",
    "plink --threads 4 --memory 16000 --bfile ldpruned_data --remove IBS_excluded.txt --make-bed --out ibd_cleaned\n",
    "\n",
    "#### Population structutre check using PCA\n",
    "\n",
    "/opt/exp_soft/bioinf/bin/plink2 --threads 4 --memory 16000 --bfile ibd_cleaned --pca 10 --out pca_results\n",
    "#### Remove bad samples..by extracting from above pca results then use --remove in plink \n",
    "\n",
    "plink --threads 4 --memory 16000 --bfile ibd_cleaned --remove bad_samples.txt --make-bed --out pca_results.eigenvec\n",
    "#### Follow up with anoiier pca analysis after removing outlines\n",
    "\n",
    "plink --file GWAS_clean4 --pheno pheno.txt --pheno-name Aff --covar plink.eigenvec --covar-name PC1 --logistic --adjust --out PC1\n",
    "\n",
    "\n",
    "### Once statisfy with the pca you can load the output in R for visualization\n",
    "\n",
    "#pca_table <- read.table(\"pca_results.eigenvec\", header=TRUE, comment.char=\"\")\n",
    "#plot(pca_table[, c(\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\")])\n",
    "plot(pca$PC1, pca$PC2, xlab=\"PC1\", ylab=\"PC2\")\n",
    "##Plot 4 pcs\n",
    "plot(pca[3:6])\n",
    "# install.packages(\"scatterplot3d\")\n",
    "library(\"scatterplot3d\")\n",
    "fsize=1br6\n",
    "pdf(\"graphs/pca_3d.pdf\", width=10, height=10)\n",
    "scatterplot3d(pca[,3:5], pch = 16, cex.symbol=1.2, color=\"#00BFC4\", main=\"Maize Diversity Panel\", angle=40)\n",
    "dev.off()\n",
    "###check sex information are ok...remove problem ones if it cannot be resolved.\n",
    "plink --threads 4 --memory 16000 --bfile pcs_results.eigenvec  --check-sex --out sexstat\n",
    "\n",
    "\n",
    "#####To remove outliners, convert eigenvectors to z scores\n",
    "##remove samples that are 2 or 3 or 6 standard deviations (SDs) from the group mean through PCA. \n",
    "\n",
    "##You can either code this manually by converting the values for a given eigenvector (i.e. principal component) to Z-scores, where Z=1 is 1 SD from the mean, Z=2 is 2 SDs, et cetera). \n",
    "\n",
    "z_scores <- (pca$PC1-mean(pca$PC1))/sd(pca$PC1)\n",
    "write.csv(z_scores, \"pc1.csv\")\n",
    "\n",
    "###Outlier samples were detected using principal component analysis (PCA) on the VST-transformed counts, where any samples>4  standard deviations from the mean, in any of the first six principal components(PC), were excluded.\n",
    "\n",
    "####Check percentage of variance explained to determined PCs to included, most consider 80-90%\n",
    "eigenvalues/sum(eigenvalues)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a727b6-664b-4d7d-b791-9749145550f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
